{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the original CSV file: 15063\n",
      "Number of rows after removing duplicates: 15063\n",
      "Number of rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # To safely evaluate strings containing Python expressions from a string-based input\n",
    "\n",
    "# Read the original main food CSV file\n",
    "df = pd.read_csv('scraped_data_food_full.csv')\n",
    "original_rows = len(df)\n",
    "print(\"Number of rows in the original CSV file: %d\" % len(df))\n",
    "\n",
    "# Remove duplicate rows with the same 'href', and adjust the index accordingly\n",
    "df.drop_duplicates(subset='href', inplace=True)\n",
    "# Reset the index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Number of rows after removing duplicates: %d\" % len(df))\n",
    "\n",
    "print(\"Number of rows removed: %d\" % (original_rows - len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a new CSV file\n",
    "df.to_csv('scraped_data_food_full_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Original Category List: 15063\n",
      "Length of Filtered Category List: 344\n",
      "Length of Not Dine-In List: 103\n"
     ]
    }
   ],
   "source": [
    "# Cleaning of dataset by categories\n",
    "\n",
    "# Read the Processed Food CSV file\n",
    "df = pd.read_csv('scraped_data_food_full_processed.csv')\n",
    "\n",
    "# Sort and obtain all the categories value in each cell and append to the list original_category_list\n",
    "original_category_list = []\n",
    "\n",
    "for i in range (0, len(df['Category'])):\n",
    "    original_category_list.append(df['Category'][i])\n",
    "\n",
    "original_category_list.sort()\n",
    "print(\"Length of Original Category List: \"+ str(len(original_category_list)))\n",
    "\n",
    "# Ensure that all the category in this Processed Food CSV dataset are sorted and only mentioned once, and then\n",
    "# stored in a new list called filtered_category_list\n",
    "\n",
    "filtered_category_list = list(set((original_category_list)))\n",
    "filtered_category_list.sort()\n",
    "print(\"Length of Filtered Category List: \"+ str(len(filtered_category_list)))\n",
    "\n",
    "# Copy filtered_category_list into not_dine_in_list\n",
    "\n",
    "not_dine_in_list = list(filtered_category_list)\n",
    "\n",
    "# Categories containing these current strings mentioned in the to_remove_keywords list will be removed from the not_dine_in_list\n",
    "\n",
    "to_remove_keywords = [\"restaurant\", \"cafe\", \"bar\", \"takeaway\", \"food court\", \"bakery\", \"pub\", \"beer\", \"patisserie\", \n",
    "                      \"creperie\", \"diner\", \"bistro\", \"live music venue\", \"hawker\", \"grill\", \"kiosk\", \"stand\", \"BBQ\",\"brewery\",\n",
    "                      \"delicatessen\", \"deli\"]\n",
    "\n",
    "\n",
    "# Search for all categories that has the string \"shop\", \"store\", and \"house\". Append the results into the newly created respective list\n",
    "category_with_word_shop = []\n",
    "category_with_word_store = []\n",
    "category_with_word_house = []\n",
    "\n",
    "for item in not_dine_in_list[:]:\n",
    "    if \"shop\" in item.lower():\n",
    "        category_with_word_shop.append(item.lower())\n",
    "    elif \"store\" in item.lower():\n",
    "        category_with_word_store.append(item.lower())\n",
    "    elif \"house\" in item.lower():\n",
    "        category_with_word_house.append(item.lower())\n",
    "\n",
    "# Exclude the string shop, townhouse complex and warehouse from the respective lists.\n",
    "category_with_word_shop.remove(\"shop\")\n",
    "category_with_word_house.remove(\"townhouse complex\")\n",
    "category_with_word_house.remove(\"warehouse\")\n",
    "\n",
    "# Join category_with_word_house list to the to_remove_keywords list\n",
    " \n",
    "to_remove_keywords.extend(category_with_word_house)\n",
    "\n",
    "\n",
    "# Remove elements that are part of the excluded_category_with_word_shop list from category_with_word_shop list\n",
    " \n",
    "excluded_category_with_word_shop = [\"shopping mall\", \"gift shop\", \"butcher shop\", \"chicken shop\", \"rice shop\"]\n",
    "\n",
    "for element in category_with_word_shop[:]:\n",
    "    if any(exclude_word in element.lower() for exclude_word in excluded_category_with_word_shop):\n",
    "       category_with_word_shop.remove(element)\n",
    "\n",
    "# Join category_with_word_shop list to the to_remove_keywords list\n",
    "       \n",
    "to_remove_keywords.extend(category_with_word_shop)\n",
    "\n",
    "\n",
    "# Remove elements that are part of the excluded_category_with_word_store list from category_with_word_store list\n",
    "\n",
    "excluded_category_with_word_store = [\"convenience store\", \"fruit and vegetable store\", \"furniture store\", \"gourmet grocery store\", \"grocery store\", \"meat products store\" ]\n",
    "\n",
    "for element in category_with_word_store[:]:  \n",
    "    if any(exclude_word in element.lower() for exclude_word in excluded_category_with_word_store):\n",
    "       category_with_word_store.remove(element)\n",
    "\n",
    "# Join category_with_word_store list to the to_remove_keywords list\n",
    "\n",
    "to_remove_keywords.extend(category_with_word_store)\n",
    "\n",
    "# Remove the categories that matches the keywords in the newly updated to_remove_keywords list\n",
    "\n",
    "not_dine_in_list = [item for item in filtered_category_list if not any(keyword in item.lower() for keyword in to_remove_keywords)]\n",
    "\n",
    "\n",
    "# Length of the not_dine_in_list after removal\n",
    "\n",
    "print(\"Length of Not Dine-In List: \" + str(len(not_dine_in_list)))\n",
    "\n",
    "\n",
    "# Remove all rows that matches the category elements in the not_dine_in_list from the CSV file\n",
    "\n",
    "df = df[~df['Category'].isin(not_dine_in_list)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Update the CSV File\n",
    "\n",
    "df.to_csv('scraped_data_food_full_processed.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Original Planning Area List: 14696\n",
      "Length of Filtered Planning Area List: 55\n",
      "['Ang Mo Kio', 'Bedok', 'Bishan', 'Boon Lay', 'Bukit Batok', 'Bukit Merah', 'Bukit Panjang', 'Bukit Timah', 'Central Water Catchment', 'Changi', 'Changi Bay', 'Choa Chu Kang', 'Clementi', 'Downtown Core', 'Geylang', 'Hougang', 'Jurong East', 'Jurong West', 'Kallang', 'Lim Chu Kang', 'Mandai', 'Marina East', 'Marina South', 'Marine Parade', 'Museum', 'Newton', 'North-Eastern Islands', 'Novena', 'Orchard', 'Outram', 'Pasir Ris', 'Paya Lebar', 'Pioneer', 'Punggol', 'Queenstown', 'River Valley', 'Rochor', 'Seletar', 'Sembawang', 'Sengkang', 'Serangoon', 'Simpang', 'Singapore River', 'Southern Islands', 'Straits View', 'Sungei Kadut', 'Tampines', 'Tanglin', 'Tengah', 'Toa Payoh', 'Tuas', 'Western Islands', 'Western Water Catchment', 'Woodlands', 'Yishun']\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column \"Region\" based on the \"Planning Area\" data column\n",
    "\n",
    "# Read the Processed Food CSV file\n",
    "\n",
    "df = pd.read_csv('scraped_data_food_full_processed.csv')\n",
    "\n",
    "# Sort and obtain all the Planning Area value in each cell and append to the list original_planning_area_list\n",
    "original_planning_area_list = []\n",
    "\n",
    "for i in range (0, len(df['Planning Area'])):\n",
    "    original_planning_area_list.append(df['Planning Area'][i])\n",
    "\n",
    "original_planning_area_list.sort()\n",
    "print(\"Length of Original Planning Area List: \"+ str(len(original_planning_area_list)))\n",
    "\n",
    "# Ensure that all the Planning area in this Processed Food CSV dataset are sorted and only mentioned once, and then\n",
    "# stored in a new list called filtered_planning_area_list\n",
    "\n",
    "filtered_planning_area_list = list(set((original_planning_area_list)))\n",
    "filtered_planning_area_list.sort()\n",
    "print(\"Length of Filtered Planning Area List: \"+ str(len(filtered_planning_area_list)))\n",
    "print(filtered_planning_area_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary Removal of Metadata Filtering\n",
    "\n",
    "# import pandas as pd\n",
    "# import ast\n",
    "# import re\n",
    "\n",
    "# df = pd.read_csv('scraped_data_food_full_processed.csv')\n",
    "\n",
    "\n",
    "# # Assuming df is your DataFrame and it already exists\n",
    "\n",
    "# # Safely convert the string representation of list of strings into a list of strings\n",
    "# df['Metadata'] = df['Metadata'].apply(ast.literal_eval)\n",
    "# # print(df[\"Metadata\"])\n",
    "\n",
    "# # Create two new columns \"Service Rating\" and \"Service Type\"\n",
    "# df['Additional Details of Location'] = None\n",
    "# df['Plus Code'] = None\n",
    "# df['Contact Number'] = None\n",
    "# df['Website'] = None\n",
    "    \n",
    "# for index, metadata_list in enumerate(df['Metadata']):\n",
    "#     # print(index)\n",
    "#     # print(metadata_list)\n",
    "\n",
    "#     for item in metadata_list:\n",
    "#         phone_number_pattern = re.compile(r'^\\d{4}\\s\\d{4}$')\n",
    "#         website_pattern= re.compile(r'^(?:[a-zA-Z0-9-]+\\.)+[a-zA-Z]{2,}$')\n",
    "#         # print(item)\n",
    "#         if phone_number_pattern.match(item):\n",
    "#             print(item)\n",
    "#             key = \"Contact Number\"\n",
    "#             df.at[index, key] = item\n",
    "#             metadata_list.remove(item)\n",
    "#         # elif website_pattern.match(item):\n",
    "#         #     print(item)\n",
    "#         #     key=\"Website\"\n",
    "#         #     df.at[index, key] = item\n",
    "#         #     metadata_list.remove(item)           \n",
    "# df\n",
    "# df.to_csv('scraped_data_food_full_processed1.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
